{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "hubs_dict = {\n",
    "    'ARICA': 'IQUIQUE',\n",
    "    'IQUIQUE': 'IQUIQUE',\n",
    "    'ANTOFAGASTA': 'ANTOFAGASTA',\n",
    "    'COPIAPO': 'COPIAPO',\n",
    "    'COQUIMBO': 'COQUIMBO',\n",
    "    'OVALLE': 'COQUIMBO',\n",
    "    'ILLAPEL': 'CURAUMA',\n",
    "    'LLAY LLAY': 'CURAUMA',\n",
    "    'CURAUMA': 'CURAUMA',\n",
    "    'SANTIAGO SUR': 'SANTIAGO SUR',\n",
    "    'RANCAGUA': 'SANTIAGO SUR',\n",
    "    'TALCA': 'TALCA',\n",
    "    'CHILLAN': 'TALCAHUANO',\n",
    "    'TALCAHUANO': 'TALCAHUANO',\n",
    "    'LOS ANGELES': 'TALCAHUANO',\n",
    "    'TEMUCO': 'TEMUCO',\n",
    "    'VALDIVIA': 'VALDIVIA',\n",
    "    'OSORNO': 'VALDIVIA',\n",
    "    'PUERTO MONTT': 'PUERTO MONTT',\n",
    "    'CASTRO': 'PUERTO MONTT',\n",
    "    'COYHAIQUE': 'COYHAIQUE',\n",
    "    'CALAMA': 'ANTOFAGASTA'\n",
    "}\n",
    "\n",
    "with open('lead_times_dict.json', 'r') as file:\n",
    "    lead_times_dict = json.load(file)\n",
    "    \n",
    "with open('S_factor_dict.json', 'r') as file:\n",
    "    S_factor_dict = json.load(file)\n",
    "\n",
    "def create_filtered_dataframe(file, HUB, n_skus):\n",
    "    datos_limpios = pd.read_csv(file)\n",
    "    datos_limpios = datos_limpios.drop(columns='Unnamed: 0')\n",
    "    datos_limpios_HUB = datos_limpios[datos_limpios['HUB'] == HUB]\n",
    "\n",
    "    top_skus = datos_limpios_HUB.groupby(by=['ID_SKU_VENTA']).sum().reset_index()\n",
    "    top_n_skus = top_skus.sort_values(by='Venta en pallets', ascending=False).head(n_skus)\n",
    "    top_n_skus_list = list(top_n_skus['ID_SKU_VENTA'])\n",
    "\n",
    "    datos_limpios_HUB_SKUS = datos_limpios_HUB[datos_limpios_HUB['ID_SKU_VENTA'].isin(top_n_skus_list)]\n",
    "    \n",
    "    return datos_limpios_HUB_SKUS\n",
    "\n",
    "\n",
    "def simulation_generator(dataframe, sS_dict, sku, cd):\n",
    "    \n",
    "    sS_info = sS_dict[(sku, cd)]\n",
    "    \n",
    "    dataframe = dataframe[(dataframe['ID_SKU_VENTA'] == sku) & (dataframe['DESCR_CENDIST'] == cd)]\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        yield row['Venta en pallets'], sS_info[0], sS_info[1]\n",
    "        \n",
    "def stats(dataframe, confianza):\n",
    "\n",
    "    mean_no_group = dataframe.groupby(by=['ID_SKU_VENTA', 'DESCR_CENDIST']).mean().reset_index().rename(columns={'Venta en pallets': 'MEDIA'})\n",
    "    stdev_no_group = dataframe.groupby(by=['ID_SKU_VENTA', 'DESCR_CENDIST']).std().reset_index().rename(columns={'Venta en pallets': 'STD'})\n",
    "    \n",
    "    mean_no_group['MEDIA'] = mean_no_group.apply(lambda x: x.MEDIA * lead_times_dict[x['DESCR_CENDIST']], axis=1)\n",
    "    stdev_no_group['STD'] = stdev_no_group.apply(lambda x: x.STD * lead_times_dict[x['DESCR_CENDIST']], axis=1)\n",
    "\n",
    "    data_completa = mean_no_group.merge(stdev_no_group, on=['ID_SKU_VENTA', 'DESCR_CENDIST'])\n",
    "    \n",
    "    data_completa['SS'] = data_completa.apply(lambda x: confianza * x['STD'], axis=1)\n",
    "\n",
    "    data_completa['s'] = data_completa.apply(lambda x: x['MEDIA'] + (confianza * x['STD']), axis=1)\n",
    "    \n",
    "    data_completa['S'] = data_completa.apply(lambda x: x['s'] * int(S_factor_dict[str(x['ID_SKU_VENTA'])]), axis=1)\n",
    "    \n",
    "    return data_completa.drop(columns=['Unnamed: 0.1_x', 'Unnamed: 0.1_y'])\n",
    "\n",
    "\n",
    "def create_sS_dict(dataframe):\n",
    "    \n",
    "    sS_dict = {}\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        sS_dict[(row['ID_SKU_VENTA'], row['DESCR_CENDIST'])] = (row['s'], row['S'])\n",
    "        \n",
    "    return sS_dict\n",
    "\n",
    "def create_grouped_dataframe(dataframe, confianza):\n",
    "    stats_no_agrupados = stats(dataframe, confianza)\n",
    "    assign_hub = lambda x: hubs_dict[x['DESCR_CENDIST']]\n",
    "    \n",
    "    datos_para_agrupar = dataframe.copy()\n",
    "    datos_para_agrupar['DESCR_CENDIST'] = datos_para_agrupar.apply(assign_hub, axis=1)\n",
    "    datos_agrupados = datos_para_agrupar.groupby(by=['ID_SKU_VENTA', 'DESCR_CENDIST', 'FECHA']).sum().reset_index()\n",
    "    \n",
    "    stats_agrupados = stats(datos_agrupados, confianza)\n",
    "    \n",
    "    todos = stats_no_agrupados.merge(stats_agrupados, on=['ID_SKU_VENTA', 'DESCR_CENDIST'], how='outer').fillna(0)\n",
    "    \n",
    "    todos.rename(columns={'MEDIA_x': 'MEDIA_NO_AGR', 'STD_x': 'STD_NO_AGR', 'STD_y': 'STD_AGR', 'SS_x': 'SS_NO_AGR', 'SS_y': 'SS_AGR'}, inplace=True)\n",
    "\n",
    "    todos = todos[['ID_SKU_VENTA', 'DESCR_CENDIST', 'MEDIA_NO_AGR', 'STD_NO_AGR', 'STD_AGR', 'SS_NO_AGR', 'SS_AGR']]\n",
    "    \n",
    "    todos.drop(columns=['STD_NO_AGR', 'STD_AGR', 'SS_NO_AGR'], inplace=True)\n",
    "    \n",
    "    todos['s'] = todos.apply(lambda x: x['MEDIA_NO_AGR'] + x['SS_AGR'], axis=1)\n",
    "    \n",
    "    todos['S'] = todos.apply(lambda x: x['s'] * int(S_factor_dict[str(x['ID_SKU_VENTA'])]), axis=1)\n",
    "    \n",
    "    return todos[['ID_SKU_VENTA', 'DESCR_CENDIST', 's', 'S']]\n",
    "        \n",
    "datos_limpios_HUB_SKUS = create_filtered_dataframe('../../data/datos_limpios_filtrados.csv', 'TALCAHUANO', 10)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_no_agrupados = stats(datos_limpios_HUB_SKUS, 1.65)\n",
    "sS_dict_no_agrupados = create_sS_dict(stats_no_agrupados)\n",
    "stats_agrupados = create_grouped_dataframe(datos_limpios_HUB_SKUS, 1.65)\n",
    "sS_dict_agrupados = create_sS_dict(stats_agrupados)\n",
    "\n",
    "generador_caso_base = simulation_generator(datos_limpios_HUB_SKUS, sS_dict_no_agrupados, 450607, 'TALCAHUANO')\n",
    "generador_caso_proyecto = simulation_generator(datos_limpios_HUB_SKUS, sS_dict_agrupados, 450607, 'TALCAHUANO')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.95, 84.57747518771248, 338.3099007508499)\n",
      "(14.95, 163.19099111236181, 652.7639644494473)\n"
     ]
    }
   ],
   "source": [
    "print(next(generador_caso_base))\n",
    "print(next(generador_caso_proyecto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>DESCR_CENDIST</th>\n",
       "      <th>ID_SKU_VENTA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>Venta en pallets</th>\n",
       "      <th>HUB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3344640</th>\n",
       "      <td>4391296</td>\n",
       "      <td>CHILLAN</td>\n",
       "      <td>622</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>4.750</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344641</th>\n",
       "      <td>4391297</td>\n",
       "      <td>CHILLAN</td>\n",
       "      <td>622</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>4.000</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344642</th>\n",
       "      <td>4391298</td>\n",
       "      <td>CHILLAN</td>\n",
       "      <td>622</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>7.125</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344643</th>\n",
       "      <td>4391299</td>\n",
       "      <td>CHILLAN</td>\n",
       "      <td>622</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>11.875</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344644</th>\n",
       "      <td>4391300</td>\n",
       "      <td>CHILLAN</td>\n",
       "      <td>622</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>4.750</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16936187</th>\n",
       "      <td>18743291</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "      <td>450607</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16936188</th>\n",
       "      <td>18743292</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "      <td>450607</td>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16936189</th>\n",
       "      <td>18743293</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "      <td>450607</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16936190</th>\n",
       "      <td>18743294</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "      <td>450607</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16936191</th>\n",
       "      <td>18743295</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "      <td>450607</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TALCAHUANO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24960 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0.1 DESCR_CENDIST  ID_SKU_VENTA       FECHA  \\\n",
       "3344640        4391296       CHILLAN           622  2018-01-02   \n",
       "3344641        4391297       CHILLAN           622  2018-01-03   \n",
       "3344642        4391298       CHILLAN           622  2018-01-04   \n",
       "3344643        4391299       CHILLAN           622  2018-01-05   \n",
       "3344644        4391300       CHILLAN           622  2018-01-06   \n",
       "...                ...           ...           ...         ...   \n",
       "16936187      18743291    TALCAHUANO        450607  2020-09-25   \n",
       "16936188      18743292    TALCAHUANO        450607  2020-09-26   \n",
       "16936189      18743293    TALCAHUANO        450607  2020-09-28   \n",
       "16936190      18743294    TALCAHUANO        450607  2020-09-29   \n",
       "16936191      18743295    TALCAHUANO        450607  2020-09-30   \n",
       "\n",
       "          Venta en pallets         HUB  \n",
       "3344640              4.750  TALCAHUANO  \n",
       "3344641              4.000  TALCAHUANO  \n",
       "3344642              7.125  TALCAHUANO  \n",
       "3344643             11.875  TALCAHUANO  \n",
       "3344644              4.750  TALCAHUANO  \n",
       "...                    ...         ...  \n",
       "16936187             0.000  TALCAHUANO  \n",
       "16936188             0.000  TALCAHUANO  \n",
       "16936189             0.000  TALCAHUANO  \n",
       "16936190             0.000  TALCAHUANO  \n",
       "16936191             0.000  TALCAHUANO  \n",
       "\n",
       "[24960 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_limpios_HUB_SKUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
