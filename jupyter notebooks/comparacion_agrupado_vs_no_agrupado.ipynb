{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import json\n",
    "import math\n",
    "import xlrd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.float_format','{:.4f}'.format)\n",
    "\n",
    "hubs_dict = {\n",
    "    'ARICA': 'IQUIQUE',\n",
    "    'IQUIQUE': 'IQUIQUE',\n",
    "    'ANTOFAGASTA': 'ANTOFAGASTA',\n",
    "    'COPIAPO': 'COPIAPO',\n",
    "    'COQUIMBO': 'COQUIMBO',\n",
    "    'OVALLE': 'COQUIMBO',\n",
    "    'ILLAPEL': 'CURAUMA',\n",
    "    'LLAY LLAY': 'CURAUMA',\n",
    "    'CURAUMA': 'CURAUMA',\n",
    "    'SANTIAGO SUR': 'SANTIAGO SUR',\n",
    "    'RANCAGUA': 'SANTIAGO SUR',\n",
    "    'TALCA': 'TALCA',\n",
    "    'CHILLAN': 'TALCAHUANO',\n",
    "    'TALCAHUANO': 'TALCAHUANO',\n",
    "    'LOS ANGELES': 'TALCAHUANO',\n",
    "    'TEMUCO': 'TEMUCO',\n",
    "    'VALDIVIA': 'VALDIVIA',\n",
    "    'OSORNO': 'VALDIVIA',\n",
    "    'PUERTO MONTT': 'PUERTO MONTT',\n",
    "    'CASTRO': 'PUERTO MONTT',\n",
    "    'COYHAIQUE': 'COYHAIQUE',\n",
    "    'CALAMA': 'ANTOFAGASTA'\n",
    "}\n",
    "\n",
    "def stats(datos):\n",
    "    \n",
    "    lead_time = 7\n",
    "\n",
    "    mean_no_group = datos.groupby(by=['ID_SKU_VENTA', 'DESCR_CENDIST']).mean().reset_index().rename(columns={'Venta en pallets': 'MEDIA'})\n",
    "    stdev_no_group = datos.groupby(by=['ID_SKU_VENTA', 'DESCR_CENDIST']).std().reset_index().rename(columns={'Venta en pallets': 'STD'})\n",
    "\n",
    "    mean_no_group['MEDIA'] = mean_no_group.apply(lambda x: x.MEDIA * lead_time, axis=1)\n",
    "    stdev_no_group['STD'] = stdev_no_group.apply(lambda x: x.STD * lead_time, axis=1)\n",
    "\n",
    "    data_completa = mean_no_group.merge(stdev_no_group, on=['ID_SKU_VENTA', 'DESCR_CENDIST'])\n",
    "\n",
    "    data_completa['COEF_VAR'] = data_completa.apply(lambda x: x['STD'] / x['MEDIA'] if x['MEDIA'] != 0 else 0, axis=1)\n",
    "\n",
    "    data_completa['SS'] = data_completa.apply(lambda x: 1.65 * x['STD'], axis=1)\n",
    "\n",
    "    data_completa['STOCK_TEORICO'] = data_completa.apply(lambda x: x['MEDIA'] + x['SS'], axis=1)\n",
    "\n",
    "    data_completa['PORCENTAJE_SS_DEL_TOTAL'] = data_completa.apply(lambda x: x['SS'] / x['STOCK_TEORICO'] if x['MEDIA'] != 0 else 0, axis=1)\n",
    "\n",
    "    porcentaje_ss_del_total = data_completa['SS'].sum() / data_completa['STOCK_TEORICO'].sum()\n",
    "    \n",
    "    return data_completa, porcentaje_ss_del_total\n",
    "\n",
    "restricted = False\n",
    "porcentaje = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_limpios = pd.read_csv('../data/datos_limpios_filtrados.csv')\n",
    "datos_limpios = datos_limpios[(datos_limpios['DESCR_CENDIST'] != 'CERVECERA') & (datos_limpios['DESCR_CENDIST'] != 'MODELO')]\n",
    "datos_limpios = datos_limpios.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_no_agrupados, porcentaje_ss_no_agrupado = stats(datos_limpios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restricted:    \n",
    "    FILE_AGRUPACIONES = f'../data/skuUnification/agrupacion_sku_{porcentaje}%.xlsx'\n",
    "    sheets_dict = pd.read_excel(FILE_AGRUPACIONES, sheet_name=None)\n",
    "\n",
    "    master = pd.DataFrame()\n",
    "    for name in sheets_dict:\n",
    "\n",
    "        df = sheets_dict[name]\n",
    "        master = pd.concat([master, df])\n",
    "\n",
    "    dict_sku_cd = {}\n",
    "    master = master.rename(columns={'SKU': 'ID_SKU_VENTA', 'CD': 'DESCR_CENDIST'})\n",
    "\n",
    "    for index, row in master.iterrows():\n",
    "\n",
    "        if row['CANTIDAD HUB 3R'] != 0:\n",
    "            dict_sku_cd[(row['ID_SKU_VENTA'], row['DESCR_CENDIST'])] = 1\n",
    "\n",
    "        else:\n",
    "            dict_sku_cd[(row['ID_SKU_VENTA'], row['DESCR_CENDIST'])] = 0\n",
    "            \n",
    "    assign_hub = (lambda x: x['DESCR_CENDIST'] if (x['ID_SKU_VENTA'], x['DESCR_CENDIST']) in \\\n",
    "                            dict_sku_cd and dict_sku_cd[(x['ID_SKU_VENTA'], x['DESCR_CENDIST'])] == 0 \\\n",
    "                            else hubs_dict[x['DESCR_CENDIST']])\n",
    "\n",
    "else:\n",
    "    assign_hub = lambda x: hubs_dict[x['DESCR_CENDIST']]\n",
    "    \n",
    "datos_para_agrupar = datos_limpios.copy()\n",
    "datos_para_agrupar['DESCR_CENDIST'] = datos_para_agrupar.apply(assign_hub, axis=1)\n",
    "datos_agrupados = datos_para_agrupar.groupby(by=['ID_SKU_VENTA', 'DESCR_CENDIST', 'FECHA']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_agrupados, porcentaje_ss_agrupado = stats(datos_agrupados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demandas = stats_agrupados.groupby(by=['ID_SKU_VENTA']).sum().reset_index()[['ID_SKU_VENTA', 'MEDIA']]\n",
    "# demandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_agrupado_agregado = stats_no_agrupados.groupby(by=['DESCR_CENDIST']).sum()[['MEDIA', 'SS', 'STOCK_TEORICO']]\n",
    "no_agrupado_agregado = no_agrupado_agregado.reset_index()\n",
    "# no_agrupado_agregado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupado_agregado = stats_agrupados.groupby(by=['DESCR_CENDIST']).sum()[['MEDIA', 'SS', 'STOCK_TEORICO']]\n",
    "agrupado_agregado = agrupado_agregado.reset_index()\n",
    "# agrupado_agregado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2843.9188887512064"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_pallets = cds_no_agrupados['STOCK_TEORICO'].sum() - cds_agrupados['STOCK_TEORICO'].sum()\n",
    "delta_pallets"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": null,
>>>>>>> 99c8fbba5c1f218120d67a6d28c44ba5e83b608c
   "metadata": {},
   "outputs": [],
   "source": [
    "if restricted:\n",
    "    diff = no_agrupado_agregado.merge(agrupado_agregado, on=['DESCR_CENDIST'], how='outer')\n",
    "    diff = diff.fillna(0)\n",
    "    diff['DELTA'] = diff['STOCK_TEORICO_y'] - diff['STOCK_TEORICO_x']\n",
    "    deltaStocks = diff[['DESCR_CENDIST', 'DELTA']]\n",
    "    \n",
    "    OUTPUT_FILE_STOCKS = f'../data/Agrupación {porcentaje}%/inventario_final_agrupacion_{porcentaje}.csv'\n",
    "    agrupado_agregado.to_csv(OUTPUT_FILE_STOCKS)\n",
    "    \n",
    "    OUTPUT_FILE_DELTAS = f'../data/Agrupación {porcentaje}%/deltas_inventario_agrupacion_{porcentaje}.csv'\n",
    "    deltaStocks.to_csv(OUTPUT_FILE_DELTAS)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_AGRUPACIONES = '../data/agrupacion_sku_70%.xlsx'\n",
    "sheets_dict = pd.read_excel(FILE_AGRUPACIONES, sheet_name=None)\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not restricted:\n",
    "    hubs = list(set(hubs_dict.values()))\n",
>>>>>>> 99c8fbba5c1f218120d67a6d28c44ba5e83b608c
    "\n",
    "    diff = no_agrupado_agregado.merge(agrupado_agregado, how='outer', on=['DESCR_CENDIST'])\n",
    "    diff = diff.fillna(0)\n",
    "    diff['DELTA'] = diff['STOCK_TEORICO_y'] - diff['STOCK_TEORICO_x']\n",
    "\n",
    "    diff['NEW_STOCK'] = 0\n",
    "\n",
    "    diff['NEW_STOCK_CD'] = diff['MEDIA_x']\n",
    "    diff['NEW_STOCK_HUB'] = diff['MEDIA_x'] + diff['SS_y']\n",
    "\n",
    "    diff = diff[['DESCR_CENDIST', 'NEW_STOCK_HUB', 'NEW_STOCK_CD']]\n",
    "\n",
    "    hubsStocks = diff[diff['DESCR_CENDIST'].isin(hubs)].reset_index()\n",
    "    hubsStocks = hubsStocks[['DESCR_CENDIST', 'NEW_STOCK_HUB']]\n",
    "    hubsStocks = hubsStocks.rename(columns={'NEW_STOCK_HUB': 'STOCK'})\n",
    "    # hubsStocks\n",
    "\n",
    "    cdStocks = diff[~diff['DESCR_CENDIST'].isin(hubs)].reset_index()\n",
    "    cdStocks = cdStocks[['DESCR_CENDIST', 'NEW_STOCK_CD']]\n",
    "    cdStocks = cdStocks.rename(columns={'NEW_STOCK_CD': 'STOCK'})\n",
    "    # cdStocks\n",
    "\n",
    "    newStocks = pd.concat([hubsStocks, cdStocks])\n",
    "    newStocks = newStocks.sort_values(by=['DESCR_CENDIST'])\n",
    "    # newStocks\n",
    "    \n",
<<<<<<< HEAD
    "    if row['CANTIDAD HUB 3R'] != 0:\n",
    "        dict_sku_cd[(row['ID_SKU_VENTA'], row['DESCR_CENDIST'])] = 1\n",
    "        \n",
    "    else:\n",
    "        dict_sku_cd[(row['ID_SKU_VENTA'], row['DESCR_CENDIST'])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_para_agrupar['DESCR_CENDIST'] = datos_para_agrupar.apply(lambda x: x['DESCR_CENDIST'] if (x['ID_SKU_VENTA'], x['DESCR_CENDIST']) in dict_sku_cd and dict_sku_cd[(x['ID_SKU_VENTA'], x['DESCR_CENDIST'])] == 0 else hubs_dict[x['DESCR_CENDIST']], axis=1)"
=======
    "    OUTPUT_FILE_STOCKS = '../data/Agrupacion total variabilidad/inventario_final_agrupacion_variabilidad_total.csv'\n",
    "    newStocks.to_csv()\n",
    "\n",
    "    oldStocks = no_agrupado_agregado[['DESCR_CENDIST', 'STOCK_TEORICO']]\n",
    "    oldStocks = oldStocks.rename(columns={'STOCK_TEORICO': 'STOCK'})\n",
    "    # oldStocks\n",
    "\n",
    "    deltaStocks = oldStocks.merge(newStocks, on='DESCR_CENDIST')\n",
    "    deltaStocks['DELTA'] = deltaStocks['STOCK_y'] - deltaStocks['STOCK_x'] \n",
    "    deltaStocks\n",
    "    deltaStocks = deltaStocks[['DESCR_CENDIST', 'DELTA']]\n",
    "    #deltaStocks\n",
    "\n",
    "    OUTPUT_FILE_DELTAS = '../data/Agrupacion total variabilidad/deltas_inventario_agrupacion_variabilidad_total.csv'\n",
    "    deltaStocks.to_csv(OUTPUT_FILE_DELTAS)"
>>>>>>> 99c8fbba5c1f218120d67a6d28c44ba5e83b608c
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hubs = list(set(hubs_dict.values()))\n",
    "\n",
    "diff = no_agrupado_agregado.merge(agrupado_agregado, how='outer', on=['DESCR_CENDIST'])\n",
    "diff = diff.fillna(0)\n",
    "diff['DELTA'] = diff['STOCK_TEORICO_y'] - diff['STOCK_TEORICO_x']\n",
    "\n",
    "diff['NEW_STOCK'] = 0\n",
    "\n",
    "diff['NEW_STOCK_CD'] = diff['MEDIA_x']\n",
    "diff['NEW_STOCK_HUB'] = diff['MEDIA_x'] + diff['SS_y']\n",
    "\n",
    "diff = diff[['DESCR_CENDIST', 'NEW_STOCK_HUB', 'NEW_STOCK_CD']]\n",
    "# diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hubsStocks = diff[diff['DESCR_CENDIST'].isin(hubs)].reset_index()\n",
    "hubsStocks = hubsStocks[['DESCR_CENDIST', 'NEW_STOCK_HUB']]\n",
    "hubsStocks = hubsStocks.rename(columns={'NEW_STOCK_HUB': 'STOCK'})\n",
    "# hubsStocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cdStocks = diff[~diff['DESCR_CENDIST'].isin(hubs)].reset_index()\n",
    "cdStocks = cdStocks[['DESCR_CENDIST', 'NEW_STOCK_CD']]\n",
    "cdStocks = cdStocks.rename(columns={'NEW_STOCK_CD': 'STOCK'})\n",
    "# cdStocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "newStocks = pd.concat([hubsStocks, cdStocks])\n",
    "newStocks = newStocks.sort_values(by=['DESCR_CENDIST'])\n",
    "newStocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oldStocks = no_agrupado_agregado[['DESCR_CENDIST', 'STOCK_TEORICO']]\n",
    "oldStocks = oldStocks.rename(columns={'STOCK_TEORICO': 'STOCK'})\n",
    "oldStocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "stats_agrupados[(stats_agrupados['MEDIA'] != 0)].to_csv('../data/stats_agrupados_limpios_70%.csv')"
=======
    "deltaStocks = oldStocks.merge(newStocks, on='DESCR_CENDIST')\n",
    "deltaStocks['DELTA'] = deltaStocks['STOCK_y'] - deltaStocks['STOCK_x'] \n",
    "deltaStocks\n",
    "deltaStocks = deltaStocks[['DESCR_CENDIST', 'DELTA']]\n",
    "\n",
    "pd.set_option('display.float_format','{:.4f}'.format)\n",
    "deltaStocks"
>>>>>>> 99c8fbba5c1f218120d67a6d28c44ba5e83b608c
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT_FILE_DELTAS = '../data/Agrupacion total variabilidad/deltas_inventario_agrupacion_variabilidad_total.csv'\n",
    "deltaStocks.to_csv(OUTPUT_FILE_DELTAS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
